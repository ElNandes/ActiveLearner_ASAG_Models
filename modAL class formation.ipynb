{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa35f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elantonfernandes/opt/anaconda3/envs/modAL_test/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09 14:09:23,506 loading file /Users/elantonfernandes/.flair/models/chunk-english/5b53097d6763734ee8ace8de92db67a1ee2528d5df9c6d20ec8e3e6f6470b423.d81b7fd7a38422f2dbf40f6449b1c63d5ae5b959863aa0c2c1ce9116902e8b22\n",
      "2022-06-09 14:09:24,919 SequenceTagger predicts: Dictionary with 45 tags: <unk>, O, B-NP, E-NP, I-NP, S-PP, S-VP, S-SBAR, S-ADVP, S-NP, S-ADJP, B-VP, E-VP, B-PP, E-PP, I-VP, S-PRT, B-ADVP, E-ADVP, B-ADJP, E-ADJP, B-CONJP, I-CONJP, E-CONJP, I-ADJP, B-SBAR, E-SBAR, S-INTJ, I-ADVP, I-PP, B-UCP, I-UCP, E-UCP, S-LST, B-PRT, I-PRT, E-PRT, S-CONJP, B-INTJ, E-INTJ, I-INTJ, B-LST, E-LST, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveLearner:\n",
    "    \n",
    "    def __init__(self, model='all-MiniLM-L6-v2', chunker=\"flair/chunk-english\", feedback_file_name):\n",
    "        self.embedder_model = SentenceTransformer(model)\n",
    "        self.tagger = SequenceTagger.load(chunker)\n",
    "        self.feedback_file_name = feedback_file_name\n",
    "        pass\n",
    "    \n",
    "    def get_uncertainty_samples(self,data,percentage,question_id):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            data: File containing the samples with question, reference answer, and student ansewer.\n",
    "            percentage: Defines the percentage of samples that need to be used in the active learnig \n",
    "                        process.\n",
    "            question_id: The question id corresponding for a set of questions.\n",
    "        \"\"\"\n",
    "        uncertain_samples_df = data.loc[(data['Answer ID']==question_id)]\n",
    "\n",
    "        return uncertain_samples_df.nsmallest(int(len(uncertain_samples_df.index)*percentage),\n",
    "                                              columns=\"Uncertainty Score\")\n",
    "    \n",
    "    def compute_uncertainty_scores(self):\n",
    "        pass\n",
    "    \n",
    "    def save_file(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, strategy, data, estimator, query_strategy):\n",
    "        if strategy == '1':\n",
    "            \n",
    "            \"\"\"\n",
    "                * Direct sentence comparison and addition of feedback and score to the whole answer.\n",
    "                * Sample student answers based on the uncertainty score (lowest first)\n",
    "                * The number of samples is decided by the percentage set by the oracle.\n",
    "                * Design the extraction based on pool based active learning to easily \n",
    "                    delete samples after they have been used for training.\n",
    "            \"\"\"\n",
    "            print(\"Applying strategy 1\")\n",
    "            #think of how to make the learners to be passed into the function and\n",
    "            #not create them here.\n",
    "            \n",
    "            feedback_learner = self.create_learner(estimator,query_strategy)\n",
    "            score_learner = self.create_learner(estimator,query_strategy)\n",
    "            \n",
    "            \n",
    "            for row_index, row_value in data.iterrows():\n",
    "                \n",
    "                query_answer = row_value['Query Answer']\n",
    "                print(\"Model answer:\\n\",query_answer)\n",
    "                \n",
    "                student_answer = row_value['Student Answer']\n",
    "                print(\"Student answer:\\n\",student_answer)\n",
    "                \n",
    "                #creating an embedding\n",
    "                student_answer_embedding = self.embedder_model.encode(student_answer)\n",
    "                \n",
    "                #acquiring feedback\n",
    "                feedback_id = self.select_add_feedback(self.feedback_file_name)\n",
    "                \n",
    "                #acquire associated score\n",
    "                print(\"\\nWhat score is assigned to this answer?\")\n",
    "                score = input(\"\\nEnter score:\\n\")\n",
    "                \n",
    "                #train the learner with this sample.\n",
    "                feedback_learner.teach(student_answer_embedding.reshape(1,-1),feedback_id)\n",
    "                score_learner.teach(student_answer_embedding.reshape(1,-1),score)\n",
    "                \n",
    "    \n",
    "        elif strategy == '2' or strategy == '3':\n",
    "            \"\"\"\n",
    "                * break down the answer into its chunks.\n",
    "                * Ask the oracle to form facts with the given chunks.\n",
    "                * Add feedback to the fact and a grade and save this to a different .csv file.\n",
    "            \"\"\"\n",
    "            print(\"Applying strategy 2\")\n",
    "            feedbacks = pd.read_csv(self.feedback_file_name)\n",
    "            for row_index, row_value in data_samples.iterrows():\n",
    "    \n",
    "                query_answer = row_value['Query Answer']\n",
    "                print(\"Model answer:\\n\",query_answer)\n",
    "\n",
    "                query_chunker = Sentence(query_answer)\n",
    "                self.tagger.predict(query_chunker)\n",
    "\n",
    "                student_answer = row_value['Student Answer']\n",
    "                print(\"Student answer:\\n\",student_answer)\n",
    "\n",
    "                passage_chunker = Sentence(student_answer)\n",
    "                self.tagger.predict(passage_chunker)\n",
    "\n",
    "                for ind,chunk in enumerate(passage_chunker.get_spans('np')):\n",
    "                    print(ind,\":\",chunk.text)\n",
    "                    \n",
    "                fact_list = list()\n",
    "                feedback_id_list = list()\n",
    "                score_list = list()\n",
    "                print(\"Select chunks to form facts from the above list\")\n",
    "                \n",
    "                while(True):\n",
    "                    chunk_list = list()\n",
    "                    fact_create = int(input(\"Do you wish to create a fact? y:1/n:0?\"))\n",
    "                    print(fact_create)\n",
    "                    if fact_create:\n",
    "\n",
    "                        while(True):\n",
    "                            inp = input(\"Enter the chunk id related to one fact or x to exit\")\n",
    "                            if inp == 'x':\n",
    "                                fact_list.append(chunk_list)\n",
    "                                break\n",
    "                            else:\n",
    "                                chunk_list.append(passage_chunker.get_spans('np')[int(inp)].text)\n",
    "\n",
    "                        #acquiring feedback\n",
    "                        feedback_id = self.select_add_feedback(self.feedback_file_name)\n",
    "                        feedback_id_list.append(feedback_id)\n",
    "                        \n",
    "                        #acquiring score\n",
    "                        print(\"\\nWhat score contribution would you associate with this fact?\")\n",
    "                        score = input(\"\\nEnter score:\\n\")\n",
    "                        score_list.append(score)\n",
    "\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                print(\"\\nFact list\",fact_list)\n",
    "                print(\"\\nFeedback list\",feedback_id_list)\n",
    "                print(\"\\nScore list\",score_list)\n",
    "                if len(fact_list)!=0:\n",
    "                    for fact_entry,feedback_entry, fact_score in zip(fact_list,feedback_id_list,score_list):\n",
    "                        text = ' '.join(fact_entry)\n",
    "                        fback = feedbacks[feedback_entry]\n",
    "                        data = [[text,fact_score,fback]]\n",
    "                        print(data)\n",
    "\n",
    "                        temp = pd.DataFrame(\n",
    "                        data = data,columns=['Fact','Score','Feedback'])\n",
    "                        fact_dataframe = pd.concat([fact_dataframe,temp],ignore_index=True)\n",
    "                        fact_dataframe.to_csv('facts_new.csv',index=False)\n",
    "                        \n",
    "                fact_dataframe = pd.read_csv('facts.csv')\n",
    "                for row_id,row_value in fact_dataframe.iterrows():\n",
    "                    fact_embedding = self.embedder_model.encode(row_value['Fact'])\n",
    "                    feedback_index = np.array([feedbacks.index(row_value['Feedback'])],dtype=int)\n",
    "                    #print(\"\\n\",type(feedback_index))\n",
    "                    score_index = np.array([score_list.index(row_value['Score'])],dtype=int)\n",
    "                    #print(type(score_index))\n",
    "                    feedback_learner.teach(fact_embedding.reshape(1,-1),feedback_index)\n",
    "                    score_learner.teach(fact_embedding.reshape(1,-1),score_index)\n",
    "        else:\n",
    "            print(\"Wrong strategy id selected.\")\n",
    "            break\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    def predict(self, data, strategy, feedback_learner, score_learner):\n",
    "        feedbacks = pd.read_csv(self.feedback_file_name)['Feedbacks']\n",
    "        if strategy == '1':\n",
    "            \n",
    "            for row_index, row_value in data.iterrows():\n",
    "                query_answer = row_value['Query Answer']\n",
    "                print(\"\\n==========================================\")\n",
    "                print(\"Model answer:\\n\",query_answer)\n",
    "                student_answer = row_value['Student Answer']\n",
    "                print(\"Student answer:\\n\",student_answer)\n",
    "                student_answer_embedding = self.embedder_model.encode(student_answer)\n",
    "                #print(\"Student answer Embedding\",student_answer_embedding.reshape(1,-1))\n",
    "\n",
    "                feedback = feedback_learner.predict(student_answer_embedding.reshape(1,-1))\n",
    "                print(\"Corresponding feedback:\\n\",feedbacks[feedback[0]])\n",
    "\n",
    "                score = score_learner.predict(student_answer_embedding.reshape(1,-1))\n",
    "                print(\"Corresponding feedback:\\n\",score)\n",
    "                \n",
    "        elif strategy == '2':\n",
    "            \n",
    "            \"\"\"\n",
    "                * model and student answer are made into chunks.\n",
    "                * linear sum asssignemnt is applied to these chunks to \n",
    "                    find the best possible pairs.\n",
    "                * The matching chunks from student answer are converted \n",
    "                    into a sentence again.\n",
    "                * This sentence is used in the active learner prediction.\n",
    "            \"\"\"\n",
    "            \n",
    "            for row_index, row_value in dataframe.iterrows():\n",
    "                \n",
    "                query_answer = row_value['Query Answer']\n",
    "                query_chunker = Sentence(query_answer)\n",
    "                self.tagger.predict(query_chunker)\n",
    "\n",
    "                student_answer = row_value['Student Answer']\n",
    "                passage_chunker = Sentence(student_answer)\n",
    "                self.tagger.predict(passage_chunker)\n",
    "\n",
    "                similarity_score_matrix = self.get_chunk_similarity_score_matrix(\n",
    "                    query_chunker.get_spans('np'),\n",
    "                    passage_chunker.get_spans('np'))\n",
    "\n",
    "                #get the linear sum assigned rows and columns for the query and passage chunks\n",
    "                row_ind, col_ind = linear_sum_assignment(similarity_score_matrix,maximize=True)\n",
    "                #print(type(row_ind), col_ind)\n",
    "                #row_ind = row_ind.sort()\n",
    "                #col_ind = col_ind.sort()\n",
    "                query_text = ' '.join([query_chunker.get_spans('np')[x].text for x in row_ind])\n",
    "                passage_text = ' '.join([passage_chunker.get_spans('np')[x].text for x in col_ind])\n",
    "                print(\"\\n===========================================================================\")\n",
    "                print(\"\\nBefore linear sum assignment\")\n",
    "                print(\"\\nQuery text:\\n\",query_answer)\n",
    "                print(\"\\nPassage text:\\n\",student_answer)\n",
    "                print(\"\\nAfter linear sum assignment.\")\n",
    "                print(\"\\nQuery text:\\n\",query_text)\n",
    "                print(\"\\nPassage text:\\n\",passage_text)\n",
    "\n",
    "                text_embed = self.embedder_model.encode(passage_text)\n",
    "                feedback_id = feedback_learner.predict(text_embed.reshape(1,-1))\n",
    "                #print(feedback_ind[0])\n",
    "                print(\"Feedback given: \",feedbacks[feedback_id[0]])\n",
    "                score = score_learner.predict(text_embed.reshape(1,-1))\n",
    "                print(\"Score given: \",score)\n",
    "\n",
    "                \"\"\"student_answer_embedding = embedder_model.encode(student_answer)\n",
    "                #print(\"Student answer Embedding\",student_answer_embedding.reshape(1,-1))\n",
    "\n",
    "                feedback = learner1.predict(student_answer_embedding.reshape(1,-1))\n",
    "                print(\"Feedback id:\",feedback)\n",
    "                print(\"Corresponding feedback\\n\",feedbacks_s1[feedback[0]])\"\"\"            \n",
    "            \n",
    "        elif strategy = '3':\n",
    "            \"\"\"\n",
    "                * student answer in converted into its individual sentences.\n",
    "                * ench sentence is passed through the active learner to get the individual feedback and score.\n",
    "            \"\"\"\n",
    "            \n",
    "            for row_index, row_value in data.iterrows():\n",
    "                student_answer = row_value['Student Answer']\n",
    "                print(\"\\n=============================================================\")\n",
    "                print(\"Student answer\",student_answer)\n",
    "                student_answer_sents = sent_tokenize(student_answer)\n",
    "\n",
    "                feedback_score_pairs = list()\n",
    "                for i,sent in enumerate(student_answer_sents):\n",
    "                    sent_embed = self.embedder_model.encode(sent)\n",
    "                    feedback_id = feedback_learner.predict(sent_embed.reshape(1,-1))\n",
    "                    score = score_learner.predict(sent_embed.reshape(1,-1))\n",
    "                    feedback_score_pairs.append([feedbacks[feedback_id[0]],score_ind[0]])\n",
    "                    print(\"\\nAssociated feedback(s) for sentence: \",i+1,\" : \",feedbacks[feedback_id[0]],\n",
    "                          \"\\n Associated score\",score)\n",
    "                \n",
    "\n",
    "    \n",
    "    def create_learner(self, estimator = RandomForestClassifier(),query_strategy=uncertainty_sampling):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            estimator: Decides which type of classifier should be used for the learning action.\n",
    "            query_strategy: Decides the form of sampling that needs to be performed on the data pool.\n",
    "        \"\"\"\n",
    "        return ActiveLearner(\n",
    "            estimator = estimator,\n",
    "            query_strategy = query_strategy)\n",
    "    \n",
    "    def select_add_feedback(self,feedback_file_name):\n",
    "        feedbacks = pd.read_csv(feedback_file_name)['Feedbacks']\n",
    "        print(\"What feedback would you give this answer?\")\n",
    "        for i,f in enumerate(feedbacks):\n",
    "            print(i,\":\",f)\n",
    "            \n",
    "        feedback_option = input(\"\\n0: Add from existing feedback.\\n1: Add new feedback.\")\n",
    "        if feedback_option == '0':\n",
    "            feedback_id = np.array([int(input(\"\\nSelect feedback ID: \"))], dtype=int)\n",
    "        elif feedback_option == '1':\n",
    "            feedback_statement = input(\"\\nEnter new feedback: \")\n",
    "\n",
    "            feedbacks.append(feedback_statement)\n",
    "            feedback_id = np.array([feedbacks.index(feedback_statement)], dtype=int)\n",
    "            print(\"feedback ID: \",feedback_id)\n",
    "        else:\n",
    "            print(\"\\nWrong ID selected: \")\n",
    "         \n",
    "        return feedback_id\n",
    "        #learner1.teach(student_answer_embedding.reshape(1,-1),feedback_id_s1)\n",
    "    \n",
    "    def generate_score(self):\n",
    "        pass\n",
    "    \n",
    "    def store_facts(self,facts_data,columns,filename):\n",
    "        facts_df = pd.DataFrame(data=facts_data,index=False)\n",
    "        facts_df.to_csv(filename,index=False)\n",
    "        pass\n",
    "    \n",
    "    def get_facts(self,filename):\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    def get_chunk_similarity_matrix(self, query_chunks, passage_chunks, threshold=0.7):\n",
    "        similarity_score_matrix = np.zeros((len(query_chunks),len(passage_chunks)))\n",
    "\n",
    "        for i,query_entity in enumerate(query_chunks):\n",
    "            for j,passage_entity in enumerate(passage_chunks):\n",
    "                \n",
    "                similarity_score = util.dot_score(\n",
    "                    self.embedder_model.encode(query_entity.text), \n",
    "                    self.embedder_model.encode(passage_entity.text))\n",
    "                \n",
    "                if similarity_score >= threshold:\n",
    "                    similarity_score_matrix[i][j]= similarity_score\n",
    "                else:\n",
    "                    similarity_score_matrix[i][j] = 0\n",
    "\n",
    "        return similarity_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62878489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78943967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b69d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
